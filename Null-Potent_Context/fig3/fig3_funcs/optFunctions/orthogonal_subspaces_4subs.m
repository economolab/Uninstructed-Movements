function [Q, Qcost, P, info, options] = orthogonal_subspaces_4subs(C1,d1,C2,d2,C3,d3,C4,d4, alpha, options)
%manifold optimization to two orthogonal subspaces that maximize the sum of variance captured.
%This file is called by other files.
%C1 = covariance matrix 1
%d1 = number of dimensions of C1 to sum in trace.
%C2 = covariance matrix 2
%d2 = number of dimensions of C2 to sum in trace.

% Written by Xiyuan Jiang and Hemant Saggar
% Date: 06/27/2020
% Modified by Munib Hasnain - added regularization to cost function
% Date: 2021-02-12

%%%%%%%%%%%%%%%%%%%%    COPYRIGHT AND LICENSE NOTICE    %%%%%%%%%%%%%%%%%%%
%    Copyright Xiyuan Jiang, Hemant Saggar, Jonathan Kao 2020
%    
%    This program is free software: you can redistribute it and/or modify
%    it under the terms of the GNU General Public License as published by
%    the Free Software Foundation, either version 3 of the License, or
%    (at your option) any later version.
%
%    This program is distributed in the hope that it will be useful,
%    but WITHOUT ANY WARRANTY; without even the implied warranty of
%    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
%    GNU General Public License for more details.
%
%    You should have received a copy of the GNU General Public License
%    along with this program.  If not, see <https://www.gnu.org/licenses/>.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% assert(isequal(C1, C1'));
% assert(isequal(C2, C2'));
assert(size(C1,1) == size(C2,1));
n = size(C1,1);
dmax = max([d1,d2,d3,d4]);
%largest magnitude eigenvalues
eigvals1 = eigs(C1, dmax, 'la'); %hoping that these all eigs are positive, still only divinding by largest algebraic +ve values
eigvals2 = eigs(C2, dmax, 'la');
eigvals3 = eigs(C3, dmax, 'la');
eigvals4 = eigs(C4, dmax, 'la');
assert(~any(eigvals1<0), 'eigvals1 <0');
assert(~any(eigvals2<0), 'eigvals2 <0');
assert(~any(eigvals3<0), 'eigvals3 <0');
assert(~any(eigvals4<0), 'eigvals4 <0');
P1 = [eye(d1); zeros(d2,d1); zeros(d3,d1); zeros(d4,d1)];
P2 = [zeros(d1,d2); eye(d2); zeros(d3,d2); zeros(d4,d2)];
P3 = [zeros(d1,d3); zeros(d2,d3); eye(d3); zeros(d4,d3)];
P4 = [zeros(d1,d4); zeros(d2,d4); zeros(d3,d4); eye(d4)];
P = {P1,P2,P3,P4};

% Create the problem structure.
manifold = stiefelfactory(n,d1+d2+d3+d4);
problem.M = manifold;
% Define the problem cost function and its Euclidean gradient.
% add regularization to discourage sparsity
problem.cost  = @(Q) -0.5*trace((Q*P1)'*C1*(Q*P1))/sum(eigvals1(1:d1))...
                     - 0.5*trace((Q*P2)'*C2*(Q*P2))/sum(eigvals2(1:d2))...
                     - 0.5*trace((Q*P3)'*C3*(Q*P3))/sum(eigvals3(1:d3))...
                     - 0.5*trace((Q*P4)'*C4*(Q*P4))/sum(eigvals4(1:d4));
%                      + alpha*(rms(norm(Q*P1)) + rms(norm(Q*P2)));
problem.egrad = @(Q) -C1*Q*(P1*P1')/sum(eigvals1(1:d1))...
                     - C2*Q*(P2*P2')/sum(eigvals2(1:d2))...
                     - C3*Q*(P3*P3')/sum(eigvals3(1:d3))...
                     - C4*Q*(P4*P4')/sum(eigvals4(1:d4));

% Numerically check gradient consistency (optional).
%checkgradient(problem);
% checkgradient(problem);
options.verbosity = 0;
% Solve.
[Q, Qcost, info, options] = trustregions(problem,[],options);

 
% Display some statistics.
% figure;
% semilogy([info.iter], [info.gradnorm], '.-');
% xlabel('Iteration number');
% ylabel('Norm of the gradient of f');

end