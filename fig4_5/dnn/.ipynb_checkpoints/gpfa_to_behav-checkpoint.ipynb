{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from decoders import DenseNN\n",
    "\n",
    "import utils\n",
    "\n",
    "import metrics\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# torch.manual_seed(123) ##For reproducibility. This will make sure that same random weights are initialized each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Load Data###\n",
    "folder = 'input_data' #ENTER THE FOLDER THAT YOUR DATA IS IN\n",
    "anm = 'JEB7'\n",
    "date = '2021-04-30'\n",
    "\n",
    "data=io.loadmat(folder + '/' + anm + '_' + date + '.mat')\n",
    "\n",
    "N = data['gpfadat'] # (time,trials,factors) of gpfa latent trajectories\n",
    "M = data['kindat']  # (time,trials,features) of kinematic features reduced with PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape N and M to be (time*trials,factors/features)\n",
    "N_reshape = N.reshape((N.shape[0]*N.shape[1],N.shape[2]))\n",
    "M_reshape = M.reshape((M.shape[0]*M.shape[1],M.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_before = 10  # How many bins of neural data prior to the output are used for decoding\n",
    "bins_current = 1  # Whether to use concurrent time bin of neural data\n",
    "bins_after = 3    # How many bins of neural data after the output are used for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for recurrent neural networks (SimpleRNN, GRU, LSTM)\n",
    "# Function to get the covariate matrix that includes spike history from previous bins\n",
    "X = utils.get_spikes_with_history(N_reshape,bins_before,bins_after,bins_current) # (time*trials,nbins,factors)\n",
    "\n",
    "# Format for  Dense Neural Network\n",
    "# Put in \"flat\" format, so each \"neuron / time\" is a single feature\n",
    "X_flat = X.reshape(X.shape[0],(X.shape[1]*X.shape[2])) # (time*trials, nbins*factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set decoding output\n",
    "y = M_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set what part of data should be part of the training/testing/validation sets\n",
    "training_range = [0, 0.7]\n",
    "testing_range = [0.7, 0.85]\n",
    "valid_range = [0.85,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples=X.shape[0]\n",
    "\n",
    "# Note that each range has a buffer of\"bins_before\" bins at the beginning, and \"bins_after\" bins at the end\n",
    "# This makes it so that the different sets don't include overlapping neural data\n",
    "training_set = np.arange(int(np.round(training_range[0]*num_examples))+bins_before,int(np.round(training_range[1]*num_examples))-bins_after)\n",
    "testing_set = np.arange(int(np.round(testing_range[0]*num_examples))+bins_before,int(np.round(testing_range[1]*num_examples))-bins_after)\n",
    "valid_set = np.arange(int(np.round(valid_range[0]*num_examples))+bins_before,int(np.round(valid_range[1]*num_examples))-bins_after)\n",
    "\n",
    "# Get training data\n",
    "X_train = X[training_set,:,:]\n",
    "X_flat_train = X_flat[training_set,:]\n",
    "y_train = y[training_set,:]\n",
    "\n",
    "# Get testing data\n",
    "X_test = X[testing_set,:,:]\n",
    "X_flat_test = X_flat[testing_set,:]\n",
    "y_test = y[testing_set,:]\n",
    "\n",
    "# Get validation data\n",
    "X_valid = X[valid_set,:,:]\n",
    "X_flat_valid = X_flat[valid_set,:]\n",
    "y_valid = y[valid_set,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score \"X\" inputs. \n",
    "X_train_mean = np.nanmean(X_train,axis=0)\n",
    "X_train_std = np.nanstd(X_train,axis=0)\n",
    "X_train = (X_train-X_train_mean)/X_train_std\n",
    "X_test = (X_test-X_train_mean)/X_train_std\n",
    "X_valid = (X_valid-X_train_mean)/X_train_std\n",
    "\n",
    "# Z-score \"X_flat\" inputs. \n",
    "X_flat_train_mean = np.nanmean(X_flat_train,axis=0)\n",
    "X_flat_train_std = np.nanstd(X_flat_train,axis=0)\n",
    "\n",
    "X_flat_train = torch.tensor( (X_flat_train-X_flat_train_mean)/X_flat_train_std )\n",
    "X_flat_test = torch.tensor( (X_flat_test-X_flat_train_mean)/X_flat_train_std )\n",
    "X_flat_valid = torch.tensor( (X_flat_valid-X_flat_train_mean)/X_flat_train_std )\n",
    "\n",
    "#Zero-center outputs\n",
    "y_train_mean = np.mean(y_train,axis=0)\n",
    "\n",
    "y_train = torch.tensor( y_train-y_train_mean )\n",
    "y_test = torch.tensor( y_test-y_train_mean )\n",
    "y_valid = torch.tensor( y_valid-y_train_mean )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = X_flat_train.shape[1]\n",
    "out_features = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNN(\n",
      "  (act): ReLU()\n",
      "  (fc1): Linear(in_features=140, out_features=100, bias=True)\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=25, bias=True)\n",
      "  )\n",
      "  (out): Linear(in_features=25, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if 'net' in locals():\n",
    "    del net\n",
    "\n",
    "## dense neural network\n",
    "units = [100,50,25] # length of units determines number of hidden layers, each with units[i] units\n",
    "# units = [200,40,5] # length of units determines number of hidden layers, each with units[i] units\n",
    "dropout = 0 # between [0,1] - probability of dropping parameters between each fully connected hidden layer\n",
    "\n",
    "net = DenseNN(in_features, out_features, units, dropout=dropout) # in_features=nNeurons, out_features=nMoveFeatures\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  ||  MSE: 2.4208970069885254\n",
      "Epoch: 500  ||  MSE: 0.8374343514442444\n",
      "Epoch: 1000  ||  MSE: 0.7782759070396423\n",
      "Epoch: 1500  ||  MSE: 0.7376005053520203\n",
      "Epoch: 2000  ||  MSE: 0.7015215754508972\n",
      "Epoch: 2500  ||  MSE: 0.6755882501602173\n",
      "Epoch: 3000  ||  MSE: 0.660599410533905\n",
      "Epoch: 3500  ||  MSE: 0.6516737937927246\n",
      "Epoch: 4000  ||  MSE: 0.6361952424049377\n",
      "Epoch: 4500  ||  MSE: 0.6415978074073792\n",
      "Epoch: 5000  ||  MSE: 0.6234473586082458\n",
      "Epoch: 5500  ||  MSE: 0.6170591711997986\n",
      "Epoch: 6000  ||  MSE: 0.6084705591201782\n",
      "Epoch: 6500  ||  MSE: 0.6045650839805603\n",
      "Epoch: 7000  ||  MSE: 0.6033021211624146\n",
      "Epoch: 7500  ||  MSE: 0.5985238552093506\n",
      "Epoch: 8000  ||  MSE: 0.5955345630645752\n",
      "Epoch: 8500  ||  MSE: 0.5921005010604858\n",
      "Epoch: 9000  ||  MSE: 0.5901634097099304\n",
      "Epoch: 9500  ||  MSE: 0.5894560217857361\n"
     ]
    }
   ],
   "source": [
    "## train network\n",
    "loss_func = nn.MSELoss()\n",
    "learning_rate = torch.tensor(1/1e3) # 0.001\n",
    "\n",
    "# optimizer = torch.optim.SGD(params=net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "net.fit(loss_func, optimizer, X_flat_train.float(), y_train.float(), epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: [[0.99379396]\n",
      " [0.78879076]\n",
      " [0.807809  ]\n",
      " [0.07398254]\n",
      " [0.34472698]\n",
      " [0.15645713]\n",
      " [0.18997109]]\n",
      "Testing R^2: [[-41.17343903]\n",
      " [ -6.30662632]\n",
      " [  0.11367953]\n",
      " [ -2.22456264]\n",
      " [ -8.44360638]\n",
      " [ -0.91415882]\n",
      " [ -2.08586669]]\n",
      "Validation R^2: [[-105.2794342 ]\n",
      " [ -13.24333382]\n",
      " [  -0.17989755]\n",
      " [  -3.76613998]\n",
      " [ -12.42126083]\n",
      " [  -1.500772  ]\n",
      " [  -3.23184252]]\n"
     ]
    }
   ],
   "source": [
    "# predict on training set\n",
    "\n",
    "y_pred = net.predict(X_flat_train.float()) ## Make Predictions on test dataset\n",
    "\n",
    "# R^2 between predictions and ground truth\n",
    "r2=metrics.get_R2(y_train.float(),y_pred)\n",
    "print('Training R^2:', r2)\n",
    "\n",
    "# predict on testing set\n",
    "\n",
    "y_pred = net.predict(X_flat_test.float()) ## Make Predictions on test dataset\n",
    "\n",
    "# R^2 between predictions and ground truth\n",
    "r2=metrics.get_R2(y_test.float(),y_pred)\n",
    "print('Testing R^2:', r2)\n",
    "\n",
    "# predict on validation set\n",
    "\n",
    "y_pred = net.predict(X_flat_valid.float()) ## Make Predictions on test dataset\n",
    "\n",
    "# R^2 between predictions and ground truth\n",
    "r2=metrics.get_R2(y_valid.float(),y_pred)\n",
    "print('Validation R^2:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "731c057a66c4905c88ca845dc7c54bc8fc359be4ee7d246ee6c27432fee6e83a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
