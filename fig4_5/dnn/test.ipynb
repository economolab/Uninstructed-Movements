{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from decoders import DenseNN\n",
    "\n",
    "import metrics\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# torch.manual_seed(123) ##For reproducibility. This will make sure that same random weights are initialized each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Munib/opt/anaconda3/envs/torchenv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## input data\n",
    "\n",
    "## output data\n",
    "X, Y = datasets.load_boston(return_X_y=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.9)\n",
    "# Y_train = Y_train.reshape(-1,1)\n",
    "# Y_test = Y_test.reshape(-1,1)\n",
    "# print(type(Y_train))\n",
    "# print(Y_test.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = torch.tensor(X_train, dtype=torch.float32),\\\n",
    "                                   torch.tensor(X_test, dtype=torch.float32),\\\n",
    "                                   torch.tensor(Y_train, dtype=torch.float32),\\\n",
    "                                   torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "samples, in_features = X_train.shape\n",
    "\n",
    "_ , out_features = Y_train.view(Y_train.shape[0],1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNN(\n",
      "  (act): ReLU()\n",
      "  (fc1): Linear(in_features=13, out_features=10, bias=True)\n",
      "  (hidden): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (1): Linear(in_features=40, out_features=5, bias=True)\n",
      "  )\n",
      "  (out): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if 'net' in locals():\n",
    "    del net\n",
    "\n",
    "## dense neural network\n",
    "units = [10,40,5] # length of units determines number of hidden layers, each with units[i] units\n",
    "# units = [200,40,5] # length of units determines number of hidden layers, each with units[i] units\n",
    "dropout = 0 # between [0,1] - probability of dropping parameters between each fully connected hidden layer\n",
    "\n",
    "net = DenseNN(in_features, out_features, units, dropout=dropout) # in_features=nNeurons, out_features=nMoveFeatures\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  ||  MSE: 745.1602172851562\n",
      "Epoch: 500  ||  MSE: 24.798704147338867\n",
      "Epoch: 1000  ||  MSE: 14.169316291809082\n",
      "Epoch: 1500  ||  MSE: 12.486102104187012\n",
      "Epoch: 2000  ||  MSE: 11.536774635314941\n",
      "Epoch: 2500  ||  MSE: 10.698667526245117\n",
      "Epoch: 3000  ||  MSE: 9.858511924743652\n",
      "Epoch: 3500  ||  MSE: 8.9229097366333\n",
      "Epoch: 4000  ||  MSE: 8.221458435058594\n",
      "Epoch: 4500  ||  MSE: 7.82087516784668\n",
      "Epoch: 5000  ||  MSE: 7.181705951690674\n",
      "Epoch: 5500  ||  MSE: 6.736398220062256\n",
      "Epoch: 6000  ||  MSE: 6.445782661437988\n",
      "Epoch: 6500  ||  MSE: 6.241292953491211\n",
      "Epoch: 7000  ||  MSE: 6.017441749572754\n",
      "Epoch: 7500  ||  MSE: 5.854900360107422\n",
      "Epoch: 8000  ||  MSE: 6.077504634857178\n",
      "Epoch: 8500  ||  MSE: 5.628582000732422\n",
      "Epoch: 9000  ||  MSE: 5.615628242492676\n",
      "Epoch: 9500  ||  MSE: 5.572151184082031\n"
     ]
    }
   ],
   "source": [
    "## train network\n",
    "loss_func = nn.MSELoss()\n",
    "learning_rate = torch.tensor(1/1e3) # 0.001\n",
    "\n",
    "# optimizer = torch.optim.SGD(params=net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "net.fit(loss_func, optimizer, X_train, Y_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: [[0.92566788]]\n"
     ]
    }
   ],
   "source": [
    "# predict on training set\n",
    "\n",
    "Y_pred = net.predict(X_test) ## Make Predictions on test dataset\n",
    "\n",
    "# R^2 between predictions and ground truth\n",
    "r2=metrics.get_R2(Y_test.view(Y_test.shape[0],1),Y_pred)\n",
    "print('R^2:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "731c057a66c4905c88ca845dc7c54bc8fc359be4ee7d246ee6c27432fee6e83a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
